{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuhkt-fqF9Pt"
   },
   "source": [
    "#  Using Variational Graph Autoencoders for Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INNiZwZEF9Pu"
   },
   "source": [
    "This tutorial demonstrates the use of Graph Auto-Encoders (GAEs) and Variational Graph Auto-Encoders (VGAEs) to perform unsupervised learning on a graph, as first implemented by <a href='https://arxiv.org/pdf/1611.07308.pdf'>Kipf (2016)</a>. The models will be implemented with PyTorch and <a href='https://pytorch-geometric.readthedocs.io/en/latest/index.html'>PyTorch Geometric</a> (a <a href='https://github.com/tkipf/gae'>tensorflow implementation</a> has been produced by the author of VGAE).\n",
    "To demonstrate the suitably of the models' embeddings, we show how unsupervised training using only the reconstruction loss improves performance on a link prediction task that the model is not directly optimising for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmFcT4OyF9Pv"
   },
   "source": [
    "## Setup\n",
    "Here we load required libraries, define paths to data, and define some helper functions. **Feel free to skip this section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hybVfUaF9Pw",
    "outputId": "e30c62f6-3395-48f2-a57b-0e049bb9b9ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-igraph in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (0.9.6)\n",
      "Requirement already satisfied: texttable>=1.6.2 in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from python-igraph) (1.6.3)\n",
      "Requirement already satisfied: torch_geometric in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (1.7.2)\n",
      "Requirement already satisfied: pandas in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from torch_geometric) (1.3.0)\n",
      "Requirement already satisfied: pyparsing in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from torch_geometric) (2.4.7)\n",
      "Requirement already satisfied: networkx in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from torch_geometric) (2.5.1)\n",
      "Requirement already satisfied: scipy in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from torch_geometric) (1.7.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from torch_geometric) (0.24.2)\n",
      "Requirement already satisfied: jinja2 in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from torch_geometric) (3.0.1)\n",
      "Requirement already satisfied: numpy in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from torch_geometric) (1.21.0)\n",
      "Requirement already satisfied: requests in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from torch_geometric) (2.25.1)\n",
      "Requirement already satisfied: googledrivedownloader in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from torch_geometric) (0.4)\n",
      "Requirement already satisfied: python-louvain in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from torch_geometric) (0.15)\n",
      "Requirement already satisfied: rdflib in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from torch_geometric) (5.0.0)\n",
      "Requirement already satisfied: tqdm in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from torch_geometric) (4.61.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from jinja2->torch_geometric) (2.0.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from networkx->torch_geometric) (4.4.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from pandas->torch_geometric) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from pandas->torch_geometric) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->torch_geometric) (1.16.0)\n",
      "Requirement already satisfied: isodate in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from rdflib->torch_geometric) (0.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from requests->torch_geometric) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from requests->torch_geometric) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from requests->torch_geometric) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from requests->torch_geometric) (1.26.6)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from scikit-learn->torch_geometric) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from scikit-learn->torch_geometric) (2.2.0)\n",
      "Requirement already satisfied: torch_scatter in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (2.0.7)\n",
      "Requirement already satisfied: torch-sparse in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (0.6.10)\n",
      "Requirement already satisfied: scipy in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from torch-sparse) (1.7.0)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from scipy->torch-sparse) (1.21.0)\n",
      "Requirement already satisfied: tensorboardX in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (2.4)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from tensorboardX) (3.17.3)\n",
      "Requirement already satisfied: numpy in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from tensorboardX) (1.21.0)\n",
      "Requirement already satisfied: six>=1.9 in /Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages (from protobuf>=3.8.0->tensorboardX) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-igraph\n",
    "!pip install torch_geometric\n",
    "!pip install torch_scatter\n",
    "!pip install torch-sparse\n",
    "!pip install tensorboardX\n",
    "\n",
    "import torch\n",
    "import igraph as ig\n",
    "import random\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from torch_geometric.nn import GCNConv, VGAE\n",
    "from torch_geometric.datasets import *\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch_geometric.nn.models.autoencoder import EPS\n",
    "MAX_LOGVAR = 10\n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn.inits import reset\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from torch_geometric.utils import (negative_sampling, remove_self_loops, add_self_loops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJSKEEqaF9Px",
    "outputId": "0731f703-bc8b-4484-dce5-f546737f8741"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f83089c2d10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seed random number generator for reproducibility\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JH266HdF9Py"
   },
   "source": [
    "## Load data\n",
    "We'll use the PubMed dataset which is accessible via PyG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_i2gS3LOF9Py",
    "outputId": "d14c3790-3484-4657-d73d-7856d5121cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0,  ..., 2, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "# load the dataset - small download on first run\n",
    "dataset_name = \"PubMed\"  # options: 'Citeseer', 'Cora', 'PubMed'\n",
    "dataset = Planetoid(root=\"./datasets/\"+dataset_name, name=dataset_name)\n",
    "data = dataset[0]\n",
    "print(data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lr7L3WUUF9Pz",
    "outputId": "18e48bad-a53e-4358-c32b-a90e2783f384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num nodes = 19717\n",
      "num edges = 88648\n",
      "num features = 500\n"
     ]
    }
   ],
   "source": [
    "# explore key features of the graph\n",
    "print('num nodes =', data.num_nodes)\n",
    "print('num edges =', data.num_edges)\n",
    "print('num features =', data.num_node_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0NKprXzF9Pz"
   },
   "source": [
    "<strong>Useful PyG Data class attributes</strong>\n",
    "<table width=\"75%\">\n",
    "    <header>\n",
    "        <th style=\"text-align:left\">Name</th>\n",
    "        <th style=\"text-align:left\">Attribute</th>\n",
    "        <th style=\"text-align:left\">Shape</th>\n",
    "    </header>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">Node Feature Matrix</td>\n",
    "        <td style=\"text-align:left\">data.x</td>\n",
    "        <td style=\"text-align:left\">(num nodes, num features)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">Edge Index</td>\n",
    "        <td style=\"text-align:left\">data.edge_index</td>\n",
    "        <td style=\"text-align:left\">(2, num edges)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\">Node Classes</td>\n",
    "        <td style=\"text-align:left\">data.y</td>\n",
    "        <td style=\"text-align:left\">(num nodes, )</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvPRL1GfF9P0"
   },
   "source": [
    "## Visualisation\n",
    "We provide a visualisation function here. Note that the 'plot' call is skipped by default, as it is slow for larger graphs. We have rendered images of these plots in section B.3 of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RL5swzxRF9P0"
   },
   "outputs": [],
   "source": [
    "# define a plot function using networkx\n",
    "def plot(data, outfile='./graph.eps'):\n",
    "    \"\"\"\n",
    "    plot a PyG graph using igraph\n",
    "    :param data: instance of torch_geometric.data\n",
    "    \"\"\"\n",
    "    assert data.edge_index is not None, 'cannot plot after train_test_split_edges has been called'\n",
    "    g = ig.Graph()\n",
    "    # set the number of vertices\n",
    "    g.add_vertices(data.num_nodes)\n",
    "    # get the edges as a list of tuples [(source, target) ...]\n",
    "    edges = list(zip(*tuple(data.edge_index)))\n",
    "    edges = [(int(a), int(b)) for a, b in edges]\n",
    "    g.add_edges(edges)\n",
    "    n_classes = len(np.unique(data.y))\n",
    "    # randomly generate a hexadecimal colour for each class\n",
    "    r = lambda: random.randint(0, 255)\n",
    "    colours = ['#%02X%02X%02X' % (r(),r(),r()) for i in range(n_classes)]\n",
    "    g.vs['color'] = [colours[cls] for cls in data.y]\n",
    "    # save the plot to a .eps file\n",
    "    ig.plot(\n",
    "        g, outfile,\n",
    "        layout=g.layout_auto(), vertex_size=15, vertex_colour='#D1D1D1',\n",
    "        edge_curved=True, bbox=(3000, 3000), margin=20\n",
    "    )\n",
    "    # read and show the plot\n",
    "    img = Image.open(outfile)\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0NRxWl0rF9P1"
   },
   "outputs": [],
   "source": [
    "# plot the graph - ok to run on cora/citeseer but slower on pubmed/reddit etc\n",
    "if data.num_nodes < 5000:\n",
    "    plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NfDzUF1F9P4"
   },
   "source": [
    "## Prepare data for edge prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dUbstNOzF9P5",
    "outputId": "7fc38a8c-93c4-4bf1-e892-35b15b7258f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True,  True,  True,  ..., False, False, False])\n",
      "tensor([1, 1, 0,  ..., 2, 0, 2])\n",
      "PubMed()\n"
     ]
    }
   ],
   "source": [
    "print(data.train_mask)\n",
    "print(data.y)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qx9S9O-KF9P6",
    "outputId": "14838b31-c56b-4474-9452-d1ab17e9b895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train edges 75352\n"
     ]
    }
   ],
   "source": [
    "# To perform edge prediction, we need to split the graph's edges intro train and test sets\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "data = train_test_split_edges(data)\n",
    "# Note that data.edge_index is no longer available, as edges have been distributed between train and test\n",
    "print('num train edges', data.train_pos_edge_index.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rx8YWbmLF9P7",
    "outputId": "fdfad531-f394-49b0-e261-0441a48f11df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Get the device to use for training our model\n",
    "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('CUDA available:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2lDDvcOwF9P7"
   },
   "outputs": [],
   "source": [
    "# We then register the relevant data to the device in use\n",
    "x = data.x.to(dev)  # feature matrix\n",
    "train_pos_edge_index = data.train_pos_edge_index.to(dev)  # index of true positive edges in the train set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eMKaiK6XF9P8",
    "outputId": "301dcef6-c10f-426d-f982-0882cc6f8b02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     0,     1,     1,     1,     2,     2,     3,     4,     5],\n",
      "        [ 1378,  1544,  2943,  8359, 10199, 10471, 11485,  8249, 14044,  1312]])\n",
      "torch.Size([2, 75352])\n",
      "torch.Size([2, 2216])\n",
      "torch.Size([2, 4432])\n"
     ]
    }
   ],
   "source": [
    "print(train_pos_edge_index[0:2,0:10])\n",
    "print(train_pos_edge_index.shape)\n",
    "print(data.val_pos_edge_index.shape)\n",
    "print(data.test_pos_edge_index.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnrsUVH6F9P8"
   },
   "source": [
    "## GAE Model\n",
    "To understand GAEs, we show the models as constructed by PyG. Alternatively, these can be imported directly from torch_geometric.nn\n",
    " \n",
    "Importantly, the GAE class includes methods to:\n",
    "<ul>\n",
    "    <li>apply the encoder and decoder</li>\n",
    "    <li>calculate reconstruction loss</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-w8D6at1F9P8"
   },
   "outputs": [],
   "source": [
    "# define the GAE class\n",
    "\n",
    "class GAE(torch.nn.Module):\n",
    "    r\"\"\"The Graph Auto-Encoder model from the\n",
    "    `\"Variational Graph Auto-Encoders\" <https://arxiv.org/abs/1611.07308>`_\n",
    "    paper based on user-defined encoder and decoder models.\n",
    "\n",
    "    Args:\n",
    "        encoder (Module): The encoder module.\n",
    "        decoder (Module, optional): The decoder module. If set to :obj:`None`,\n",
    "            will default to the\n",
    "            :class:`torch_geometric.nn.models.InnerProductDecoder`.\n",
    "            (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder=None):\n",
    "        super(GAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = InnerProductDecoder() if decoder is None else decoder\n",
    "        GAE.reset_parameters(self)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        reset(self.encoder)\n",
    "        reset(self.decoder)\n",
    "\n",
    "\n",
    "    def encode(self, *args, **kwargs):\n",
    "        r\"\"\"Runs the encoder and computes node-wise latent variables.\"\"\"\n",
    "        return self.encoder(*args, **kwargs)\n",
    "\n",
    "\n",
    "    def decode(self, *args, **kwargs):\n",
    "        r\"\"\"Runs the decoder and computes edge probabilities.\"\"\"\n",
    "        return self.decoder(*args, **kwargs)\n",
    "\n",
    "\n",
    "    def recon_loss(self, z, pos_edge_index):\n",
    "        r\"\"\"Given latent variables :obj:`z`, computes the binary cross\n",
    "        entropy loss for positive edges :obj:`pos_edge_index` and negative\n",
    "        sampled edges.\n",
    "\n",
    "        Args:\n",
    "            z (Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            pos_edge_index (LongTensor): The positive edges to train against.\n",
    "        \"\"\"\n",
    "\n",
    "        # print('recon_loss in')\n",
    "        pos_loss = -torch.log(\n",
    "            self.decoder(z, pos_edge_index, sigmoid=True) + EPS).mean()\n",
    "\n",
    "        # Do not include self-loops in negative samples\n",
    "        pos_edge_index, _ = remove_self_loops(pos_edge_index)\n",
    "        pos_edge_index, _ = add_self_loops(pos_edge_index)\n",
    "\n",
    "        neg_edge_index = negative_sampling(pos_edge_index, z.size(0))\n",
    "        neg_loss = -torch.log(1 -\n",
    "                              self.decoder(z, neg_edge_index, sigmoid=True) +\n",
    "                              EPS).mean()\n",
    "\n",
    "        # print('recon_loss out')\n",
    "        return pos_loss + neg_loss\n",
    "\n",
    "\n",
    "    def test(self, z, pos_edge_index, neg_edge_index):\n",
    "        r\"\"\"Given latent variables :obj:`z`, positive edges\n",
    "        :obj:`pos_edge_index` and negative edges :obj:`neg_edge_index`,\n",
    "        computes area under the ROC curve (AUC) and average precision (AP)\n",
    "        scores.\n",
    "\n",
    "        Args:\n",
    "            z (Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            pos_edge_index (LongTensor): The positive edges to evaluate\n",
    "                against.\n",
    "            neg_edge_index (LongTensor): The negative edges to evaluate\n",
    "                against.\n",
    "        \"\"\"\n",
    "        # print('test in')\n",
    "        pos_y = z.new_ones(pos_edge_index.size(1))\n",
    "        neg_y = z.new_zeros(neg_edge_index.size(1))\n",
    "        y = torch.cat([pos_y, neg_y], dim=0)\n",
    "\n",
    "        pos_pred = self.decoder(z, pos_edge_index, sigmoid=True)\n",
    "        neg_pred = self.decoder(z, neg_edge_index, sigmoid=True)\n",
    "        pred = torch.cat([pos_pred, neg_pred], dim=0)\n",
    "\n",
    "        y, pred = y.detach().cpu().numpy(), pred.detach().cpu().numpy()\n",
    "\n",
    "        # print('test out')\n",
    "        return roc_auc_score(y, pred), average_precision_score(y, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6jMB3ZRNF9P9"
   },
   "outputs": [],
   "source": [
    "# define the encoder and decoder that GAE will use\n",
    "# this code is slightly adapted from the PyG example to accept model_name\n",
    "class GAEEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GAEEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        return self.conv2(x, edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkKlk7wmF9P9"
   },
   "source": [
    "### InnerProductDecoder\n",
    "The inner product decoder from the `\"Variational Graph Auto-Encoders\"<https://arxiv.org/abs/1611.07308>`_ paper\n",
    "\n",
    "$\\sigma(\\mathbf{Z}\\mathbf{Z}^{\\top})$\n",
    "\n",
    "where $\\mathbf{Z} \\in \\mathbb{R}^{N \\times d}$ denotes the latent space produced by the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "tcM14DF8F9P_"
   },
   "outputs": [],
   "source": [
    "# To decode embeddings and attempt input reconstruction, we can use the standard InnerProductDecoder\n",
    "class InnerProductDecoder(torch.nn.Module):\n",
    "    r\"\"\"The inner product decoder from the `\"Variational Graph Auto-Encoders\"\n",
    "    <https://arxiv.org/abs/1611.07308>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\sigma(\\mathbf{Z}\\mathbf{Z}^{\\top})\n",
    "\n",
    "    where :math:`\\mathbf{Z} \\in \\mathbb{R}^{N \\times d}` denotes the latent\n",
    "    space produced by the encoder.\"\"\"\n",
    "    def forward(self, z, edge_index, sigmoid=True):\n",
    "        r\"\"\"Decodes the latent variables :obj:`z` into edge probabilities for\n",
    "        the given node-pairs :obj:`edge_index`.\n",
    "\n",
    "        Args:\n",
    "            z (Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            sigmoid (bool, optional): If set to :obj:`False`, does not apply\n",
    "                the logistic sigmoid function to the output.\n",
    "                (default: :obj:`True`)\n",
    "        \"\"\"\n",
    "        # print('forward called')\n",
    "        value = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=1)\n",
    "        return torch.sigmoid(value) if sigmoid else value\n",
    "\n",
    "    def forward_all(self, z, sigmoid=True):\n",
    "        r\"\"\"Decodes the latent variables :obj:`z` into a probabilistic dense\n",
    "        adjacency matrix.\n",
    "\n",
    "        Args:\n",
    "            z (Tensor): The latent space :math:`\\mathbf{Z}`.\n",
    "            sigmoid (bool, optional): If set to :obj:`False`, does not apply\n",
    "                the logistic sigmoid function to the output.\n",
    "                (default: :obj:`True`)\n",
    "        \"\"\"\n",
    "        print('forward_all called')\n",
    "        adj = torch.matmul(z, z.t())\n",
    "        return torch.sigmoid(adj) if sigmoid else adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lA4X6tsGF9P_"
   },
   "outputs": [],
   "source": [
    "# bring the encoder and decoder together to compile the GAE\n",
    "# in_channels (the dimensionality of the input data) is simply the number of features\n",
    "# we define out_channels (the dimensionality of the latent vector or embedding) as 16\n",
    "gae = GAE(GAEEncoder(in_channels=dataset.num_features, out_channels=16)).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "_s6xFybtF9QA"
   },
   "outputs": [],
   "source": [
    "# define the optimizer with a learning rate of 0.01\n",
    "gae_optimizer = torch.optim.Adam(gae.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "umdeJ7RNF9QA"
   },
   "outputs": [],
   "source": [
    "# define a writer to log training results\n",
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9dVStbCF9QB"
   },
   "source": [
    "Although we will train the GAE in an unsupervised manner (using reconstruction loss) <i>we can validate its performance by testing its ability to perform link prediction during training </i> (even though this is not used in back propagation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "GS336lDiF9QB"
   },
   "outputs": [],
   "source": [
    "# define a function to test our predictions against the ground truth edges\n",
    "def test(model, pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "QeLcHu7zF9QB"
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "def train_gae():\n",
    "    print('training gae')\n",
    "    auc, ap = None, None\n",
    "    for epoch in range(0, 200):\n",
    "        gae_optimizer.zero_grad()\n",
    "        # get the embedding (z) of each node, shape(num_nodes, channels)\n",
    "        z = gae.encode(x, train_pos_edge_index)\n",
    "        # calculate the reconstruction loss to be used in backprop\n",
    "        loss = gae.recon_loss(z, train_pos_edge_index)\n",
    "        loss.backward()\n",
    "        gae_optimizer.step()\n",
    "\n",
    "        writer.add_scalar(\"loss\", loss.item(), epoch)\n",
    "\n",
    "        # calculate performance on edge prediction task\n",
    "        auc, ap = test(gae, data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "        writer.add_scalar(\"AUC\", auc, epoch)\n",
    "        writer.add_scalar(\"AP\", ap, epoch)\n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "            print((z[train_pos_edge_index[0]] * z[train_pos_edge_index[1]]).sum(dim=1))\n",
    "    return auc, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8RX--yrF9QB",
    "outputId": "68773aed-f75d-4e79-ef13-e383ec5dab2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training gae\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SB/opt/miniconda3/envs/gnn_tutorial/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, AUC: 0.8848, AP: 0.8679\n",
      "tensor([0.0018, 0.0015, 0.0010,  ..., 0.0062, 0.0014, 0.0046],\n",
      "       grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "train_gae()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SLaXDWmF9QC"
   },
   "source": [
    "## VGAE Model\n",
    "To understand VGAEs, we again show the model as constructed by PyG (torch_geometric.nn.VGAE).\n",
    " \n",
    "VGAE differs from GAE in the use of two GCNs that encode the mean and variance. This allows it to reconstruct unseen inputs but requires a few updates to the main class.\n",
    "Namely:\n",
    "<ul>\n",
    "    <li>we use a KL loss, which uses the reconstruction loss from GAEs but adds a term to measure the probability distributions</li>\n",
    "    <li>the encoder uses the reparametrisation trick in order to maintain a differentiable loss function </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HgOALzDbF9QC"
   },
   "outputs": [],
   "source": [
    "# define the VGAE class, which inherits from GAE \n",
    "\n",
    "class VGAE(GAE):\n",
    "    r\"\"\"The Variational Graph Auto-Encoder model from the\n",
    "    `\"Variational Graph Auto-Encoders\" <https://arxiv.org/abs/1611.07308>`_\n",
    "    paper.\n",
    "\n",
    "    Args:\n",
    "        encoder (Module): The encoder module to compute :math:`\\mu` and\n",
    "            :math:`\\log\\sigma^2`.\n",
    "        decoder (Module, optional): The decoder module. If set to :obj:`None`,\n",
    "            will default to the\n",
    "            :class:`torch_geometric.nn.models.InnerProductDecoder`.\n",
    "            (default: :obj:`None`)\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder=None):\n",
    "        super(VGAE, self).__init__(encoder, decoder)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            return mu + torch.randn_like(logvar) * torch.exp(logvar)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def encode(self, *args, **kwargs):\n",
    "        \"\"\"\"\"\"\n",
    "        self.__mu__, self.__logvar__ = self.encoder(*args, **kwargs)\n",
    "        self.__logvar__ = self.__logvar__.clamp(max=MAX_LOGVAR)\n",
    "        z = self.reparametrize(self.__mu__, self.__logvar__)\n",
    "        return z\n",
    "\n",
    "    def kl_loss(self, mu=None, logvar=None):\n",
    "        r\"\"\"Computes the KL loss, either for the passed arguments :obj:`mu`\n",
    "        and :obj:`logvar`, or based on latent variables from last encoding.\n",
    "\n",
    "        Args:\n",
    "            mu (Tensor, optional): The latent space for :math:`\\mu`. If set to\n",
    "                :obj:`None`, uses the last computation of :math:`mu`.\n",
    "                (default: :obj:`None`)\n",
    "            logvar (Tensor, optional): The latent space for\n",
    "                :math:`\\log\\sigma^2`.  If set to :obj:`None`, uses the last\n",
    "                computation of :math:`\\log\\sigma^2`.(default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        mu = self.__mu__ if mu is None else mu\n",
    "        logvar = self.__logvar__ if logvar is None else logvar.clamp(\n",
    "            max=MAX_LOGVAR)\n",
    "        return -0.5 * torch.mean(\n",
    "            torch.sum(1 + logvar - mu**2 - logvar.exp(), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "petz3lOeF9QC"
   },
   "outputs": [],
   "source": [
    "# define a new encoder which incorporates new GCN layers for embedding the probability distribution\n",
    "class VGAEEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(VGAEEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "        self.conv_logvar = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        return self.conv_mu(x, edge_index), self.conv_logvar(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PozuVVedF9QC"
   },
   "outputs": [],
   "source": [
    "# bring the encoder and decoder together to compile the VGAE\n",
    "# in_channels (the dimensionality of the input data) is simply the number of features\n",
    "# we define out_channels (the dimensionality of the latent vector or embedding) as 16\n",
    "vgae = VGAE(VGAEEncoder(in_channels=dataset.num_features, out_channels=16)).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J1-z0JxRF9QD"
   },
   "outputs": [],
   "source": [
    "# define a new optimizer with vgae params\n",
    "vgae_optimizer = torch.optim.Adam(vgae.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VgYq46vWF9QD"
   },
   "outputs": [],
   "source": [
    "def train_vgae():\n",
    "    print('training vgae')\n",
    "    auc, ap = None, None\n",
    "    for epoch in range(200):\n",
    "        vgae_optimizer.zero_grad()\n",
    "        # get the embedding (z) of each node, shape(num_nodes, channels)\n",
    "        z = vgae.encode(x, train_pos_edge_index)\n",
    "        # calculate reconstruction loss\n",
    "        recon_loss = vgae.recon_loss(z, train_pos_edge_index)\n",
    "        # calculate kl loss\n",
    "        kl_loss = vgae.kl_loss()\n",
    "        # multiply the two losses, ensuring output is nonzero\n",
    "        loss = recon_loss + (1 / data.num_nodes) * kl_loss\n",
    "        loss.backward()\n",
    "        vgae_optimizer.step()\n",
    "\n",
    "        writer.add_scalar(\"loss\", loss.item(), epoch)\n",
    "\n",
    "        # calculate performance on edge prediction task\n",
    "        auc, ap = test(vgae, data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "        writer.add_scalar(\"AUC\", auc, epoch)\n",
    "        writer.add_scalar(\"AP\", ap, epoch)\n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    return auc, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-KcMNs1F9QE",
    "outputId": "a88800ba-1075-4864-cd3b-f345ad839e31"
   },
   "outputs": [],
   "source": [
    "train_vgae()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vi2kIHnF9QE"
   },
   "source": [
    "## Experiments\n",
    "We will now run each model 10 times over the dataset in order to robustly compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wrzVkkliF9QE",
    "outputId": "223acb3d-0012-4491-efbd-1c3f710b83dd"
   },
   "outputs": [],
   "source": [
    "print('running experiments on', dataset_name)\n",
    "gae_results = []\n",
    "vgae_results = []\n",
    "n_experiments = 10\n",
    "for i in range(n_experiments):\n",
    "    print(i + 1)\n",
    "    gae_results.append(train_gae())\n",
    "    vgae_results.append(train_vgae())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H3IOQLNAF9QE",
    "outputId": "96cd3ed5-9036-4950-9cd3-c295637a6505",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('GAE results')\n",
    "gae_aucs, gae_aps = list(zip(*gae_results))\n",
    "print('AUC: mean = %0.3f, std = %0.3f' % (np.mean(gae_aucs), np.std(gae_aucs)))\n",
    "print('AP : mean = %0.3f, std = %0.3f' % (np.mean(gae_aps), np.std(gae_aps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wRE-GBTyF9QE",
    "outputId": "b050701b-9dc0-4351-e88f-69309224338c"
   },
   "outputs": [],
   "source": [
    "print('VGAE results')\n",
    "vgae_aucs, vgae_aps = list(zip(*vgae_results))\n",
    "print('AUC: mean = %0.3f, std = %0.3f' % (np.mean(vgae_aucs), np.std(vgae_aucs)))\n",
    "print('AP : mean = %0.3f, std = %0.3f' % (np.mean(vgae_aps), np.std(vgae_aps)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuV3e-5iF9QF"
   },
   "source": [
    "Note the comparable AUC and means. On average, the VGAE is slightly more performant on other graphs such as Cora and Citeseer. This is likely because PubMed uses the more descriptive TF-IDF word vector, which accounts for the frequency of terms. This feature maybe more discriminative, and thus more useful when learning vertex embeddings."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "b3-vgae.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gnn_tutorial",
   "language": "python",
   "name": "gnn_tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
